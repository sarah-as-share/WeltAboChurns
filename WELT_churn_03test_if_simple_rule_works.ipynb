{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%pylab inline\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['datetime']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%pylab inline\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# Page Impressions\n",
    "piDat = pd.read_csv('../data/PI_angereicherteDaten.csv.txt',sep='\\t',low_memory=False,na_values=['-'])\n",
    "# Visits\n",
    "vDat = pd.read_csv('../data/V_angereicherteDaten.txt',sep='\\t',low_memory=False,na_values=['-'])\n",
    "\n",
    "# contract data from contracts which are of interest to us\n",
    "contract = pd.read_pickle('contract_data') \n",
    "\n",
    "# date handling\n",
    "dateparse1 = lambda x: pd.datetime.strptime(x, '%d.%m.%Y')\n",
    "dateparse2 = lambda x: pd.datetime.strptime(x, '%m/%d/%Y')\n",
    "\n",
    "# from piDat and vDat make pivot tables for each KPI of interest such that each line represents one user, \n",
    "# columns represent weeks\n",
    "#\n",
    "# filter for subscriptions of interest ('Vollabo' & WeltPlus etc., no strange cancellation reasons)\n",
    "#\n",
    "\n",
    "# lists of variable names for new pivot tbales and lists of colnumns names in original data\n",
    "list_pi_varNames = ['v','vPlus','pi','piComment','piSection','piArticle','piPlusComment','piPlusArticle']\n",
    "list_pi_colNames = ['Visits', 'Visits Plus',\n",
    " 'Page Impressions', 'Page Impressions plus' ,'PI [mit Komment]',\n",
    " 'PI [Typ: Section]', 'PI [Typ: Article] ', 'PI Plus [mit Komment]',\n",
    " 'PI Plus [Typ: Section]' ,'PI Plus [Typ: Article]']\n",
    "\n",
    "list_v_varNames = ['vComment','vSection','vArticle','vMobile','vDesktop',\n",
    "                   'vPlusComment','vPlusArticle','vPlusMobile','vPlusDesktop']\n",
    "list_v_colNames = ['Visits [mit Komment]', 'Visits [mit Section] ','Visits [mit Article] ', \n",
    "                   'Visits [Mobile] ', 'Visits [Desktop] ', \n",
    "                   'Visits Plus [mit Komment]', 'Visits Plus [mit Article]',\n",
    "                   'Visits Plus [Mobile]', 'Visits Plus [Desktop]']\n",
    "\n",
    "# list of IDs from subscriptions of interest\n",
    "conIdx = contract['WT SSOID']\n",
    "\n",
    "\n",
    "# contains in the end all pivot tables\n",
    "pivot_tables_pi_v = {}\n",
    "\n",
    "# from piDat\n",
    "for idx, val in enumerate(list_pi_varNames):\n",
    "    # make pivot table\n",
    "    table = pd.pivot_table(piDat,values=list_pi_colNames[idx], \n",
    "                                  index='URM - Eigene Besucher-ID', columns='Wochen',aggfunc='first')\n",
    "    # filter\n",
    "    pivot_tables_pi_v[val] = table.loc[table.index.isin(conIdx)]\n",
    "    \n",
    "# fom vDat\n",
    "for idx, val in enumerate(list_v_varNames):\n",
    "    # make pivot table\n",
    "    table = pd.pivot_table(vDat, values=list_v_colNames[idx], \n",
    "                                  index='URM - Eigene Besucher-ID', columns='Wochen',aggfunc='first')\n",
    "    # filter\n",
    "    pivot_tables_pi_v[val] = table.loc[table.index.isin(conIdx)]\n",
    "\n",
    "    \n",
    "# make relations with v\n",
    "list_total = list_pi_varNames[1:]+list_v_varNames\n",
    "for idx, val in enumerate(list_total):\n",
    "    # name to save table\n",
    "    table_name= val + '_per_v'\n",
    "    # make relations\n",
    "    pivot_tables_pi_v[table_name] = pivot_tables_pi_v[val]/pivot_tables_pi_v['v']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtab=pivot_tables_pi_v['pi_per_v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_if_classification_works(dat, begin_week, begin_year, end_week, end_year):\n",
    "    \n",
    "    #print(dat.name)\n",
    "    con_begin = contract.loc[dat.name,'VB Tag']\n",
    "    con_canc = contract.loc[dat.name,'K Tag']\n",
    "    \n",
    "    one_month_after_canc_day = con_begin+timedelta(days=30) # one_month_after_canc_day = 'OMacD'\n",
    "    oMacD_week = one_month_after_canc_day.weekofyear\n",
    "    oMacD_year = one_month_after_canc_day.year\n",
    "    \n",
    "    if (oMacD_year<begin_year) | ((oMacD_year==begin_year) & (oMacD_week < (begin_week + 4)) ):\n",
    "        oMacD_week = begin_week + 4\n",
    "        oMacD_year = begin_year\n",
    "    \n",
    "    # make list of weeks from\n",
    "    all_weeks=list(dat.index)\n",
    "    all_weeks=[x.split('_')[0] for x in all_weeks if len(x.split('_'))==1 ]\n",
    "    \n",
    "    first_idx = str(oMacD_year) + '/' + str((oMacD_week+1)).zfill(2)\n",
    "    if first_idx=='2017/53':\n",
    "        first_idx = '2018/01'\n",
    "    first = all_weeks.index(first_idx)\n",
    "    \n",
    "    \n",
    "    weeks_to_iterate = all_weeks[first:]\n",
    "    \n",
    "    for week in weeks_to_iterate:\n",
    "        \n",
    "        week_now = int(week.split('/')[1])\n",
    "        year_now = int(week.split('/')[0])\n",
    "        \n",
    "        # preparation\n",
    "        idxWeek = all_weeks.index(week)    \n",
    "        week_before = all_weeks[idxWeek-1]\n",
    "        \n",
    "        mean_until_now = dat.loc[all_weeks[:idxWeek]].mean()\n",
    "        median_until_now = dat.loc[all_weeks[:idxWeek]].median()\n",
    "        sd_until_now = dat.loc[all_weeks[:idxWeek]].std()\n",
    "        \n",
    "        #print(week)\n",
    "        \n",
    "        zsc = (dat.loc[week] - mean_until_now )/sd_until_now \n",
    "        prz = dat.loc[week]/median_until_now \n",
    "        \n",
    "        week_before_zsc_flag = all_weeks[idxWeek-1] + '_zsc_flag'\n",
    "        week_now_zsc_flag = week + '_zsc_flag'\n",
    "        week_before_prz_flag = all_weeks[idxWeek-1] + '_prz_flag'\n",
    "        week_now_prz_flag = week + '_prz_flag'\n",
    "        \n",
    "        week_now_zsc_churn = week + '_zsc_churn'\n",
    "        week_now_prz_churn = week + '_prz_churn'\n",
    "        \n",
    "              \n",
    "        # setting flags for alert: prz\n",
    "        if (zsc < 2) & (dat[week_before_zsc_flag] == 'empty'):\n",
    "            dat[week_now_zsc_flag] = 'flag1'\n",
    "        if (zsc < 2) & (dat[week_before_zsc_flag] == 'flag1'):\n",
    "            dat[week_now_zsc_flag] = 'flag2'\n",
    "        if (zsc < 2) & (dat[week_before_zsc_flag] == 'flag2'):\n",
    "            dat[week_now_zsc_flag] = 'flag2'\n",
    "            \n",
    "            # flag indicates churn            \n",
    "            \n",
    "            # comparison if flag correctly set -> different cases\n",
    "            \n",
    "            # 1st there is no cancellation at all: 'wrong'\n",
    "            if pd.isnull(contract.loc[dat.name,'K Tag']):\n",
    "                dat[week_now_zsc_churn] = 'wrong'\n",
    "            \n",
    "            else:\n",
    "                # 2nd look at cancellation date\n",
    "                week_canc = con_canc.weekofyear \n",
    "                year_canc = con_canc.year\n",
    "            \n",
    "            \n",
    "                if ((year_now - year_canc)==0) & ((week_canc-week_now)<-1):\n",
    "                    dat.loc[week_now_zsc_churn] = 'too_late'\n",
    "                elif ((year_now - year_canc)==0) & ((week_canc-week_now)>4):\n",
    "                    dat.loc[week_now_zsc_churn] = 'too_early'\n",
    "                else:\n",
    "                    dat.loc[week_now_zsc_churn] = 'correct'\n",
    "            \n",
    "        \n",
    "       \n",
    "        # setting flags for alert: zsc\n",
    "        if (prz < 2) & (dat[week_before_prz_flag] == 'empty'):\n",
    "            dat.loc[week_now_prz_flag] = 'flag1'\n",
    "        if (prz < 2) & (dat[week_before_prz_flag] == 'flag1'):\n",
    "            dat.loc[week_now_prz_flag] = 'flag2'\n",
    "        if (prz < 2) & (dat[week_before_prz_flag] == 'flag2'):\n",
    "            dat.loc[week_now_prz_flag] = 'flag2'\n",
    "            \n",
    "            # flag indicates churn            \n",
    "            \n",
    "            # comparison if flag correctly set -> different cases\n",
    "            \n",
    "            # 1st there is no cancellation at all: 'wrong'\n",
    "            if pd.isnull(contract.loc[dat.name,'K Tag']):\n",
    "                dat.loc[week_now_prz_churn] = 'wrong'\n",
    "            \n",
    "            else:            \n",
    "                # 2nd look at cancellation date\n",
    "                week_canc = con_canc.weekofyear \n",
    "                year_canc = con_canc.year\n",
    "                        \n",
    "                if (((year_now - year_canc)==0) & ((week_canc-week_now)<-1)):\n",
    "                    dat.loc[week_now_prz_churn] = 'too_late'\n",
    "                elif (((year_now - year_canc)==0) & ((week_canc-week_now)>4)):\n",
    "                    dat[week_now_prz_churn] = 'too_early'\n",
    "                else:\n",
    "                    dat.loc[week_now_prz_churn] = 'correct'\n",
    "                    \n",
    "                          \n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = vtab.columns.values\n",
    "cols_prz_flag = [x+'_prz_flag' for x in cols]\n",
    "cols_zsc_flag = [x+'_zsc_flag' for x in cols]\n",
    "\n",
    "cols_prz_churn = [x+'_prz_churn' for x in cols]\n",
    "cols_zsc_churn = [x+'_zsc_churn' for x in cols]\n",
    "\n",
    "col_tot = cols_prz_flag +cols_zsc_flag+cols_prz_churn+cols_zsc_churn\n",
    "\n",
    "vdat = vtab.copy()\n",
    "\n",
    "for col in col_tot:\n",
    "    vdat[col] = 'empty'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-08 17:03:45.875345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:42: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1018: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-08 17:10:35.867241\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "vdat = vdat.apply(test_if_classification_works, axis=1, args=(47, 2017, 21, 2018))\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2017/47', '2017/48', '2017/49', '2017/50', '2017/51', '2017/52',\n",
       "       '2018/01', '2018/02', '2018/03', '2018/04', '2018/05', '2018/06',\n",
       "       '2018/07', '2018/08', '2018/09', '2018/10', '2018/11', '2018/12',\n",
       "       '2018/13', '2018/14', '2018/15', '2018/16', '2018/17', '2018/18',\n",
       "       '2018/19', '2018/20', '2018/21', '2017/47_prz_flag',\n",
       "       '2017/48_prz_flag', '2017/49_prz_flag', '2017/50_prz_flag',\n",
       "       '2017/51_prz_flag', '2017/52_prz_flag', '2018/01_prz_flag',\n",
       "       '2018/02_prz_flag', '2018/03_prz_flag', '2018/04_prz_flag',\n",
       "       '2018/05_prz_flag', '2018/06_prz_flag', '2018/07_prz_flag',\n",
       "       '2018/08_prz_flag', '2018/09_prz_flag', '2018/10_prz_flag',\n",
       "       '2018/11_prz_flag', '2018/12_prz_flag', '2018/13_prz_flag',\n",
       "       '2018/14_prz_flag', '2018/15_prz_flag', '2018/16_prz_flag',\n",
       "       '2018/17_prz_flag', '2018/18_prz_flag', '2018/19_prz_flag',\n",
       "       '2018/20_prz_flag', '2018/21_prz_flag', '2017/47_zsc_flag',\n",
       "       '2017/48_zsc_flag', '2017/49_zsc_flag', '2017/50_zsc_flag',\n",
       "       '2017/51_zsc_flag', '2017/52_zsc_flag', '2018/01_zsc_flag',\n",
       "       '2018/02_zsc_flag', '2018/03_zsc_flag', '2018/04_zsc_flag',\n",
       "       '2018/05_zsc_flag', '2018/06_zsc_flag', '2018/07_zsc_flag',\n",
       "       '2018/08_zsc_flag', '2018/09_zsc_flag', '2018/10_zsc_flag',\n",
       "       '2018/11_zsc_flag', '2018/12_zsc_flag', '2018/13_zsc_flag',\n",
       "       '2018/14_zsc_flag', '2018/15_zsc_flag', '2018/16_zsc_flag',\n",
       "       '2018/17_zsc_flag', '2018/18_zsc_flag', '2018/19_zsc_flag',\n",
       "       '2018/20_zsc_flag', '2018/21_zsc_flag', '2017/47_prz_churn',\n",
       "       '2017/48_prz_churn', '2017/49_prz_churn', '2017/50_prz_churn',\n",
       "       '2017/51_prz_churn', '2017/52_prz_churn', '2018/01_prz_churn',\n",
       "       '2018/02_prz_churn', '2018/03_prz_churn', '2018/04_prz_churn',\n",
       "       '2018/05_prz_churn', '2018/06_prz_churn', '2018/07_prz_churn',\n",
       "       '2018/08_prz_churn', '2018/09_prz_churn', '2018/10_prz_churn',\n",
       "       '2018/11_prz_churn', '2018/12_prz_churn', '2018/13_prz_churn',\n",
       "       '2018/14_prz_churn', '2018/15_prz_churn', '2018/16_prz_churn',\n",
       "       '2018/17_prz_churn', '2018/18_prz_churn', '2018/19_prz_churn',\n",
       "       '2018/20_prz_churn', '2018/21_prz_churn', '2017/47_zsc_churn',\n",
       "       '2017/48_zsc_churn', '2017/49_zsc_churn', '2017/50_zsc_churn',\n",
       "       '2017/51_zsc_churn', '2017/52_zsc_churn', '2018/01_zsc_churn',\n",
       "       '2018/02_zsc_churn', '2018/03_zsc_churn', '2018/04_zsc_churn',\n",
       "       '2018/05_zsc_churn', '2018/06_zsc_churn', '2018/07_zsc_churn',\n",
       "       '2018/08_zsc_churn', '2018/09_zsc_churn', '2018/10_zsc_churn',\n",
       "       '2018/11_zsc_churn', '2018/12_zsc_churn', '2018/13_zsc_churn',\n",
       "       '2018/14_zsc_churn', '2018/15_zsc_churn', '2018/16_zsc_churn',\n",
       "       '2018/17_zsc_churn', '2018/18_zsc_churn', '2018/19_zsc_churn',\n",
       "       '2018/20_zsc_churn', '2018/21_zsc_churn'], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdat.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wochen\n",
       "2017/48_prz_churn       0\n",
       "2017/49_prz_churn       0\n",
       "2017/50_prz_churn       0\n",
       "2017/51_prz_churn       0\n",
       "2017/52_prz_churn       0\n",
       "2018/01_prz_churn       0\n",
       "2018/02_prz_churn    2937\n",
       "2018/03_prz_churn    3153\n",
       "2018/04_prz_churn    3301\n",
       "2018/05_prz_churn    3427\n",
       "2018/06_prz_churn    3535\n",
       "2018/07_prz_churn    3637\n",
       "2018/08_prz_churn    3809\n",
       "2018/09_prz_churn    3883\n",
       "2018/10_prz_churn    3897\n",
       "2018/11_prz_churn    3901\n",
       "2018/12_prz_churn    3878\n",
       "2018/13_prz_churn    3825\n",
       "2018/14_prz_churn    3773\n",
       "2018/15_prz_churn    3746\n",
       "2018/16_prz_churn    3712\n",
       "2018/17_prz_churn    3684\n",
       "2018/18_prz_churn    3624\n",
       "2018/19_prz_churn    3613\n",
       "2018/20_prz_churn    3601\n",
       "dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(vdat.iloc[:,82 : 107]=='wrong')\n",
    "#list(vdat.columns.values).index('2018/21_prz_churn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
