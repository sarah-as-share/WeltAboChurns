{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model wird trainiert mit einem verkleinerten Feature set trainiert um den Anforderungen des neu gezogenen Datensatzes zu gen√ºgen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['datetime']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "%pylab inline\n",
    "\n",
    "dat_all_wBehav, dat_long_wBehav, dat_short_wBehav = pickle.load(open('dat_to_train_wlastBehav_reducedFeat.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from datetime import datetime\n",
    "\n",
    "# prepare data\n",
    "keys = ['dat_all_wBehav', 'dat_long_wBehav', 'dat_short_wBehav']\n",
    "dats = [dat_all_wBehav, dat_long_wBehav, dat_short_wBehav]\n",
    "\n",
    "dat_train = {}\n",
    "dat_test = {}\n",
    "label_train = {}\n",
    "label_test = {}\n",
    "for idx, key in enumerate(keys):\n",
    "    label = dats[idx]['dat_abs_gauss_final']['Kuendigungsstatus']\n",
    "    dat_cp = dats[idx]['dat_abs_gauss_final'].drop(columns = ['Kuendigungsstatus','Newsletter'])\n",
    "    \n",
    "    dat_train_, dat_test_, label_train_, label_test_ = train_test_split(dat_cp, label, test_size=0.2, random_state=42)\n",
    "    dat_train[key] = dat_train_\n",
    "    dat_test[key] = dat_test_\n",
    "    label_train[key] = label_train_\n",
    "    label_test[key] = label_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:44:28.806563\n",
      "dat_all_wBehav\n",
      "18:44:46.437242\n",
      "dat_long_wBehav\n",
      "18:44:56.025785\n",
      "dat_short_wBehav\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "classifiers = {}\n",
    "for key in keys:\n",
    "    \n",
    "    print(datetime.now().time())\n",
    "    print(key)\n",
    "\n",
    "    classifiers[key] = GradientBoostingClassifier( n_estimators = 800 )\n",
    "    classifiers[key].fit(dat_train[key], label_train[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "import pickle\n",
    "pickle.dump( classifiers['dat_all_wBehav'], open( \"real_prediction/trainedModel.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred_train={}\n",
    "pred_test ={}\n",
    "\n",
    "for key in keys:\n",
    "    pred_train[key] = classifiers[key].predict(dat_train[key])\n",
    "    pred_test[key] = classifiers[key].predict(dat_test[key])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Training with n_estimators = 800 ###\n",
      "#########################\n",
      "dat_all_wBehav\n",
      "#########################\n",
      "TRAINING SET\n",
      "\n",
      "Predicted     gekuendigt  ungekuendigt   All\n",
      "True                                        \n",
      "gekuendigt          1693            17  1710\n",
      "ungekuendigt           6          5108  5114\n",
      "All                 1699          5125  6824\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  gekuendigt       1.00      0.99      0.99      1710\n",
      "ungekuendigt       1.00      1.00      1.00      5114\n",
      "\n",
      " avg / total       1.00      1.00      1.00      6824\n",
      "\n",
      "#########################\n",
      "TEST SET\n",
      "\n",
      "Predicted     gekuendigt  ungekuendigt   All\n",
      "True                                        \n",
      "gekuendigt           408            27   435\n",
      "ungekuendigt           2          1269  1271\n",
      "All                  410          1296  1706\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  gekuendigt       1.00      0.94      0.97       435\n",
      "ungekuendigt       0.98      1.00      0.99      1271\n",
      "\n",
      " avg / total       0.98      0.98      0.98      1706\n",
      "\n",
      "#########################\n",
      "dat_long_wBehav\n",
      "#########################\n",
      "TRAINING SET\n",
      "\n",
      "Predicted     gekuendigt  ungekuendigt   All\n",
      "True                                        \n",
      "gekuendigt           109             0   109\n",
      "ungekuendigt           0          3167  3167\n",
      "All                  109          3167  3276\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  gekuendigt       1.00      1.00      1.00       109\n",
      "ungekuendigt       1.00      1.00      1.00      3167\n",
      "\n",
      " avg / total       1.00      1.00      1.00      3276\n",
      "\n",
      "#########################\n",
      "TEST SET\n",
      "\n",
      "Predicted     gekuendigt  ungekuendigt  All\n",
      "True                                       \n",
      "gekuendigt            15             9   24\n",
      "ungekuendigt           2           794  796\n",
      "All                   17           803  820\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  gekuendigt       0.88      0.62      0.73        24\n",
      "ungekuendigt       0.99      1.00      0.99       796\n",
      "\n",
      " avg / total       0.99      0.99      0.99       820\n",
      "\n",
      "#########################\n",
      "dat_short_wBehav\n",
      "#########################\n",
      "TRAINING SET\n",
      "\n",
      "Predicted     gekuendigt  ungekuendigt  All\n",
      "True                                       \n",
      "gekuendigt           127             0  127\n",
      "ungekuendigt           0           526  526\n",
      "All                  127           526  653\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  gekuendigt       1.00      1.00      1.00       127\n",
      "ungekuendigt       1.00      1.00      1.00       526\n",
      "\n",
      " avg / total       1.00      1.00      1.00       653\n",
      "\n",
      "#########################\n",
      "TEST SET\n",
      "\n",
      "Predicted     gekuendigt  ungekuendigt  All\n",
      "True                                       \n",
      "gekuendigt            34             4   38\n",
      "ungekuendigt           2           124  126\n",
      "All                   36           128  164\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  gekuendigt       0.94      0.89      0.92        38\n",
      "ungekuendigt       0.97      0.98      0.98       126\n",
      "\n",
      " avg / total       0.96      0.96      0.96       164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('#### Training with n_estimators = 800 ###')\n",
    "\n",
    "for key in keys:\n",
    "    print('#########################')\n",
    "    print(key)\n",
    "    print('#########################')\n",
    "    print('TRAINING SET')\n",
    "    print('')\n",
    "    print(pd.crosstab(label_train[key], pred_train[key], rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "    print()\n",
    "    print(classification_report(label_train[key], pred_train[key]))\n",
    "    print('#########################')\n",
    "    print('TEST SET')\n",
    "    print('')\n",
    "    print(pd.crosstab(label_test[key], pred_test[key], rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "    print()\n",
    "    print(classification_report(label_test[key], pred_test[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
